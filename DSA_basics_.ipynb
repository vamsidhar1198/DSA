{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUHqxarVbeknyn4OzgLxL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsidhar1198/DSA/blob/main/DSA_basics_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is DSA ?**"
      ],
      "metadata": {
        "id": "XhvZCysEihn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSA (Data Structures and Algorithms) is a fundamental concept in computer science. It forms the building block for efficient programs that can handle and process information."
      ],
      "metadata": {
        "id": "YSd9cc0Eif5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data Structures:**"
      ],
      "metadata": {
        "id": "gCoYj2J1ioqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Data structures are specialized formats for organizing, storing, and accessing data. They determine how efficiently you can perform operations like adding, removing, searching, or sorting elements. Here are some common data structures:\n",
        "\n",
        "* **Arrays:** A fixed-size collection of elements of the same data type. Random access is fast, but insertion/deletion in the middle can be slow.\n",
        "* **Linked Lists:** A linear collection of elements where each element (node) contains data and a reference to the next node. Insertion/deletion is easier but random access is slow. There are different types of linked lists like singly linked lists, doubly linked lists, and circular linked lists, each with specific use cases.\n",
        "* **Stacks:** LIFO (Last In First Out) principle - elements are added and removed from the top. Useful for implementing undo/redo functionality, function calls, etc.\n",
        "* **Queues:** FIFO (First In First Out) principle - elements are added at the back and removed from the front. Useful for processing tasks in a specific order, like job scheduling or managing printer queues.\n",
        "* **Trees:** Hierarchical data structure with a root node, child nodes, and so on. Useful for representing hierarchical relationships, sorting elements, and efficient searching.\n",
        "* **Hash Tables:** Use a hash function to map keys to values. Enables fast access and insertion based on the key. Useful for implementing dictionaries, caches, etc.\n",
        "* **Heaps:** Tree-based structure where the element at the root node has a specific property (largest/smallest) compared to its children. Useful for implementing priority queues and efficient sorting algorithms like heap sort.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DB1Q7kzniW2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Algorithms:**"
      ],
      "metadata": {
        "id": "tfbGQyaai0XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Algorithms are a set of well-defined instructions for solving a specific problem. They take input, process it, and produce an output. Here are different categories of algorithms based on their functionality:\n",
        "\n",
        "* **Searching Algorithms:** Find a specific element within a data structure. Examples include linear search (iterative through elements), binary search (divide-and-conquer on sorted data).\n",
        "* **Sorting Algorithms:** Arrange elements in a specific order (ascending/descending). Examples include bubble sort (repeatedly swap adjacent elements), insertion sort (insert elements into their correct position), merge sort (divide-and-conquer by splitting and merging), quick sort (partitioning and sorting sub-arrays).\n",
        "* **Graph Algorithms:** Work on graph data structures (nodes connected by edges) to find shortest paths, traverse the graph, or identify connected components. Examples include Dijkstra's algorithm (shortest path), Breadth-First Search (BFS - explore all neighbor nodes level by level), Depth-First Search (DFS - explore as far as possible on a single path before backtracking)."
      ],
      "metadata": {
        "id": "9IbFWiyJiy7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Big O**"
      ],
      "metadata": {
        "id": "pO9NcrYGjcHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big O notation is a crucial concept in computer science for analyzing algorithm efficiency. It describes how the runtime of an algorithm grows with respect to the input size"
      ],
      "metadata": {
        "id": "ehmR8wyrjat_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**What is Big O Notation?**"
      ],
      "metadata": {
        "id": "ZIDrcQvmjr9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Big O notation (written as O(f(n))) tells us the upper bound on how fast the number of operations in an algorithm scales as the input size (n) increases. It ignores constant factors and lower-order terms, focusing on the dominant growth rate.\n",
        "\n",
        "**How to Analyze Big O Notation:**\n",
        "\n",
        "1. **Identify the Dominant Term:** Examine the algorithm and find the operation that executes the most as the input size grows. Ignore constant factors multiplying the operation and focus on the order of growth (e.g., n vs. n^2).\n",
        "2. **Determine the Order of Growth:** Common order of growths include:\n",
        "   - **Constant Time (O(1))**: The number of operations stays constant regardless of input size (e.g., accessing an element by index in an array).\n",
        "   - **Linear Time (O(n))**: The number of operations grows linearly with the input size (e.g., iterating through a list of size n).\n",
        "   - **Logarithmic Time (O(log n))**: The number of operations grows logarithmically with the input size. This is typically faster than linear time (e.g., binary search on a sorted array).\n",
        "   - **Quadratic Time (O(n^2))**: The number of operations grows quadratically with the input size (e.g., bubble sort). This can become slow for large inputs.\n",
        "   - **Polynomial Time (O(n^k))**: The number of operations grows proportionally to some power (k) of the input size (e.g., matrix multiplication).\n",
        "   - **Exponential Time (O(2^n))**: The number of operations grows exponentially with the input size. This is generally undesirable due to rapid performance degradation (e.g., brute-force search for some problems).\n",
        "   - **Factorial Time (O(n!))**: The number of operations grows very rapidly as the input size increases. This is typically avoided for practical algorithms due to its slowness (e.g., traveling salesperson problem).\n",
        "\n"
      ],
      "metadata": {
        "id": "Z56Yo-7yjT6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Examples of Big O Notation:**"
      ],
      "metadata": {
        "id": "mtqCi2pjj-xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Linear Search (O(n))**: Iterates through each element in a list/array until the target element is found. As the list size (n) increases, the number of comparisons (operations) grows linearly.\n",
        "2. **Binary Search (O(log n))**: Divides the sorted list in half repeatedly until the target element is found. The number of comparisons grows logarithmically with the list size.\n",
        "3. **Selection Sort (O(n^2))**: Compares each element with every other element to find the minimum and swap it to the front. The number of comparisons grows quadratically with the input size.\n",
        "4. **Insertion Sort (O(n^2))**: Inserts each element into its correct position in a sorted list. The number of comparisons and shifts grow quadratically with the input size.\n",
        "5. **Merge Sort (O(n log n))**: Divides the list into sub-lists, sorts them recursively, and merges them back. The divide-and-conquer approach achieves a more efficient logarithmic growth factor for comparisons.\n",
        "\n",
        "\n",
        "\n",
        "Big O notation helps us compare algorithms and choose the most efficient one for a specific problem. It allows us to predict how well an algorithm will scale for larger inputs. Understanding Big O notation is essential for designing and analyzing efficient algorithms."
      ],
      "metadata": {
        "id": "_HBYE4t-j9dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![\"Alt text for your image\"](https://drive.google.com/uc?export=view&id=1I9iHTCgPAzDe7j9vM6Wb5PdBzjiccb3S)\n"
      ],
      "metadata": {
        "id": "lx7m_awLlsdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How time complexity is calculated ?"
      ],
      "metadata": {
        "id": "l97O4aUHohVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![\"Alt text for your image\"](https://drive.google.com/uc?export=view&id=1QTmtQq0uTs-3BwXJEA2roWrCjuLUFJ93)\n"
      ],
      "metadata": {
        "id": "AKVUvzvyly9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example how we can calculate the time complexity for the code.\n",
        "\n",
        "* Example-1 : Let's consider the getting squared numbers for the list given so we use a for loop to get the result, here time complexity o(n) as it has to iterate through each and every element in the list\n",
        "\n",
        "* Example-2 : Let's consider we are trying to detect an duplicate element in the list, the code is given below we have used 2 loops for checking all the elements of the list considering one element from the list so the time complexity will be o(n^2)\n",
        "\n",
        "* Example-3 : Let's consider the code below which has two pieces of code, where one has two loops which is n^2 iterations and second has one loop which can loop for n iterations. when you combine this codes the time complextiy can be\n",
        "\n",
        "      time = a * n^2 + b * n +c\n",
        "\n",
        "      1. Keep only the fastest grwoing terms (as we can see as n goes ⬆️ then the fastest growing term will be n^2 only, so we can remove b*n + c )\n",
        "\n",
        "      time = a * n^2\n",
        "\n",
        "      2. Dropping the constant\n",
        "\n",
        "      time = n^2\n",
        "\n",
        "      O(n^2)"
      ],
      "metadata": {
        "id": "_8czHWdXp6S3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![\"Alt text for your image\"](https://drive.google.com/uc?export=view&id=1uU0iUaLWh6FKGj1ERlLjHr9T5sLtGeYY)"
      ],
      "metadata": {
        "id": "7C-ddIWRp30D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "colab link : https://colab.research.google.com/drive/1e8wvUGTWgr8shlbkpWgS6SK5KAWhi8c-?usp=sharing"
      ],
      "metadata": {
        "id": "E9MhtHZjxt1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1whhZ8pgh1i5"
      },
      "outputs": [],
      "source": []
    }
  ]
}